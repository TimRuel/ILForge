üìå Logging to experiments/exp_v5.2.0/simulations/sim_01/iter_0324/logs/slurm_log.out
git-lfs/3.3.0 (GitHub; linux amd64; go 1.20.3)
üîÅ Running Iteration 324 of Simulation sim_01 in Experiment exp_v5.2.0 (poisson / group_rates_weighted_sum/ fixed_effects_regression) with 64 cores...
[INFO] True parameters already exist ‚Äî skipping generation.
Generating data...
[‚úì] Saved config snapshot to: /gpfs/home/tbr0780/ILForge/experiments/exp_v5.2.0/simulations/sim_01/iter_0324/config_snapshot.yml
[INFO] Generating new data for iteration: iter_0324
[‚úì] Saved simulated data to: /gpfs/home/tbr0780/ILForge/experiments/exp_v5.2.0/simulations/sim_01/iter_0324/data
[INFO] Saved objects: data, X
Executing iteration...
üîç Computing branch parameters...
‚úÖ Branch parameters computed (3.33 min)
üîç Running integrated likelihood...
‚úÖ Integrated likelihood complete (28.28 min)
üìà Running profile likelihood...
‚úÖ Profile likelihood complete (6.07 min)
‚è±Ô∏è  Total experiment time: 37.68 minutes
‚úì Experiment results saved to /experiments/exp_v5.2.0/simulations/sim_01/iter_0324/results
‚úì Iteration completed
‚úÖ SLURM iteration complete: iter_0324
===== FINAL DIAGNOSTICS for Job 4491023 =====
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-17:10:24 core-walltime
Job Wall-clock time: 00:38:36
Memory Utilized: 0.00 MB
Memory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:38:36 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-17:10:24 core-walltime
Job Wall-clock time: 00:38:36
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
JobID                     JobName    Elapsed     MaxRSS     ReqMem  AllocCPUS      State 
------------ -------------------- ---------- ---------- ---------- ---------- ---------- 
4490034_323        experiment_sim   00:38:37                   64G         64    RUNNING 
4490034_323+                batch   00:38:37                               64    RUNNING 
4490034_323+               extern   00:38:37                               64    RUNNING 
              total        used        free      shared  buff/cache   available
Mem:          251Gi        21Gi        77Gi       8.0Gi       152Gi       213Gi
Swap:          31Gi       8.0Mi        31Gi
 16:39:47 up 11 days,  4:24,  0 users,  load average: 1.60, 6.22, 24.66
top - 16:39:47 up 11 days,  4:24,  0 users,  load average: 1.60, 6.22, 24.66
Tasks: 708 total,   1 running, 707 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.0 us,  0.2 sy,  0.0 ni, 99.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
MiB Mem : 257574.3 total,  78996.4 free,  22317.3 used, 156260.6 buff/cache
MiB Swap:  32768.0 total,  32759.7 free,      8.3 used. 219041.1 avail Mem 

    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
      1 root      20   0  238432  11172   8368 S   0.0   0.0   1:38.26 systemd
      2 root      20   0       0      0      0 S   0.0   0.0   0:00.27 kthreadd
      3 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 rcu_gp
      4 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 rcu_par+
      5 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 slub_fl+
      7 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker+
     11 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 mm_perc+
     12 root      20   0       0      0      0 S   0.0   0.0   0:00.00 rcu_tas+
     13 root      20   0       0      0      0 S   0.0   0.0   0:00.00 rcu_tas+
     14 root      20   0       0      0      0 S   0.0   0.0   0:04.98 ksoftir+
     15 root      20   0       0      0      0 I   0.0   0.0   4:46.08 rcu_sch+
     16 root      rt   0       0      0      0 S   0.0   0.0   0:00.55 migrati+
     17 root      rt   0       0      0      0 S   0.0   0.0   0:00.13 watchdo+
     18 root      20   0       0      0      0 S   0.0   0.0   0:00.32 cpuhp/0
     19 root      20   0       0      0      0 S   0.0   0.0   0:00.00 cpuhp/1
     20 root      rt   0       0      0      0 S   0.0   0.0   0:00.40 watchdo+
     21 root      rt   0       0      0      0 S   0.0   0.0   0:00.67 migrati+
     22 root      20   0       0      0      0 S   0.0   0.0   0:02.84 ksoftir+
     24 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker+
     25 root      20   0       0      0      0 S   0.0   0.0   0:00.00 cpuhp/2
     26 root      rt   0       0      0      0 S   0.0   0.0   0:00.40 watchdo+
     27 root      rt   0       0      0      0 S   0.0   0.0   0:00.64 migrati+
     28 root      20   0       0      0      0 S   0.0   0.0   0:02.68 ksoftir+
     30 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker+
     31 root      20   0       0      0      0 S   0.0   0.0   0:00.00 cpuhp/3
     32 root      rt   0       0      0      0 S   0.0   0.0   0:00.40 watchdo+
     33 root      rt   0       0      0      0 S   0.0   0.0   0:00.63 migrati+
     34 root      20   0       0      0      0 S   0.0   0.0   0:02.80 ksoftir+
     36 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker+
     37 root      20   0       0      0      0 S   0.0   0.0   0:00.00 cpuhp/4
     38 root      rt   0       0      0      0 S   0.0   0.0   0:00.40 watchdo+
     39 root      rt   0       0      0      0 S   0.0   0.0   0:00.62 migrati+
     40 root      20   0       0      0      0 S   0.0   0.0   0:02.46 ksoftir+
===== BACKGROUND CHECKJOB MONITOR LOG =====
===== checkjob (interval) at Sun Sep 21 16:01:53 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:00:43 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 00:45:52 core-walltime
Job Wall-clock time: 00:00:43
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:02:27 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:01:23 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 01:29:36 core-walltime
Job Wall-clock time: 00:01:24
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:03:05 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:01:55 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 02:03:44 core-walltime
Job Wall-clock time: 00:01:56
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:03:36 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:02:27 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 02:36:48 core-walltime
Job Wall-clock time: 00:02:27
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:04:08 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:02:58 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 03:10:56 core-walltime
Job Wall-clock time: 00:02:59
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:04:39 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:03:29 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 03:44:00 core-walltime
Job Wall-clock time: 00:03:30
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:05:10 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:04:00 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 04:17:04 core-walltime
Job Wall-clock time: 00:04:01
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:05:44 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:04:40 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 05:01:52 core-walltime
Job Wall-clock time: 00:04:43
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:06:24 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:05:14 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 05:36:00 core-walltime
Job Wall-clock time: 00:05:15
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:06:55 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:05:46 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 06:09:04 core-walltime
Job Wall-clock time: 00:05:46
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:07:27 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:06:17 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 06:43:12 core-walltime
Job Wall-clock time: 00:06:18
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:07:59 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:06:49 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 07:16:16 core-walltime
Job Wall-clock time: 00:06:49
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:08:30 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:07:20 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 07:49:20 core-walltime
Job Wall-clock time: 00:07:20
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:09:01 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:07:51 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 08:23:28 core-walltime
Job Wall-clock time: 00:07:52
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:09:33 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:08:23 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 08:57:36 core-walltime
Job Wall-clock time: 00:08:24
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:10:05 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:08:55 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 09:31:44 core-walltime
Job Wall-clock time: 00:08:56
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:10:36 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:09:27 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 10:04:48 core-walltime
Job Wall-clock time: 00:09:27
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:11:08 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:09:58 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 10:38:56 core-walltime
Job Wall-clock time: 00:09:59
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:11:40 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:10:30 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 11:13:04 core-walltime
Job Wall-clock time: 00:10:31
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:12:12 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:11:02 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 11:47:12 core-walltime
Job Wall-clock time: 00:11:03
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:12:43 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:11:34 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 12:20:16 core-walltime
Job Wall-clock time: 00:11:34
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:13:15 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:12:41 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 13:32:48 core-walltime
Job Wall-clock time: 00:12:42
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:14:23 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:13:13 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 14:06:56 core-walltime
Job Wall-clock time: 00:13:14
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:14:54 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:13:45 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 14:40:00 core-walltime
Job Wall-clock time: 00:13:45
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:15:26 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:14:16 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 15:14:08 core-walltime
Job Wall-clock time: 00:14:17
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:15:58 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:14:48 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 15:48:16 core-walltime
Job Wall-clock time: 00:14:49
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:16:30 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:15:20 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 16:22:24 core-walltime
Job Wall-clock time: 00:15:21
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:17:02 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:15:52 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 16:56:32 core-walltime
Job Wall-clock time: 00:15:53
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:17:33 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:16:24 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 17:29:36 core-walltime
Job Wall-clock time: 00:16:24
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:18:05 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:16:55 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 18:03:44 core-walltime
Job Wall-clock time: 00:16:56
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:18:37 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:17:27 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 18:37:52 core-walltime
Job Wall-clock time: 00:17:28
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:19:09 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:17:59 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 19:12:00 core-walltime
Job Wall-clock time: 00:18:00
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:19:41 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:18:31 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 19:46:08 core-walltime
Job Wall-clock time: 00:18:32
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:20:12 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:19:02 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 20:19:12 core-walltime
Job Wall-clock time: 00:19:03
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:20:44 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:19:34 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 20:53:20 core-walltime
Job Wall-clock time: 00:19:35
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:21:16 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:20:06 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 21:27:28 core-walltime
Job Wall-clock time: 00:20:07
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:21:47 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:20:38 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 22:00:32 core-walltime
Job Wall-clock time: 00:20:38
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:22:19 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:21:09 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 22:34:40 core-walltime
Job Wall-clock time: 00:21:10
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:22:51 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:21:41 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 23:08:48 core-walltime
Job Wall-clock time: 00:21:42
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:23:23 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:22:13 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 23:41:52 core-walltime
Job Wall-clock time: 00:22:13
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:23:54 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:22:44 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-00:17:04 core-walltime
Job Wall-clock time: 00:22:46
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:24:26 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:23:16 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-00:50:08 core-walltime
Job Wall-clock time: 00:23:17
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:24:58 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:23:48 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-01:23:12 core-walltime
Job Wall-clock time: 00:23:48
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:25:29 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:24:19 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-01:56:16 core-walltime
Job Wall-clock time: 00:24:19
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:26:00 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:24:50 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-02:29:20 core-walltime
Job Wall-clock time: 00:24:50
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:26:30 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:25:21 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-03:02:24 core-walltime
Job Wall-clock time: 00:25:21
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:27:01 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:25:51 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-03:35:28 core-walltime
Job Wall-clock time: 00:25:52
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:27:32 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:26:22 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-04:08:32 core-walltime
Job Wall-clock time: 00:26:23
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:28:03 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:26:53 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-04:41:36 core-walltime
Job Wall-clock time: 00:26:54
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:28:34 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:27:24 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-05:13:36 core-walltime
Job Wall-clock time: 00:27:24
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:29:05 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:27:55 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-05:46:40 core-walltime
Job Wall-clock time: 00:27:55
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:29:35 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:28:25 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-06:19:44 core-walltime
Job Wall-clock time: 00:28:26
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:30:06 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:28:58 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-06:53:52 core-walltime
Job Wall-clock time: 00:28:58
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:30:39 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:29:29 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-07:26:56 core-walltime
Job Wall-clock time: 00:29:29
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:31:09 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:29:59 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-08:00:00 core-walltime
Job Wall-clock time: 00:30:00
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:31:40 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:30:30 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-08:33:04 core-walltime
Job Wall-clock time: 00:30:31
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:32:11 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:31:01 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-09:05:04 core-walltime
Job Wall-clock time: 00:31:01
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:32:42 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:31:32 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-09:38:08 core-walltime
Job Wall-clock time: 00:31:32
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:33:13 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:32:03 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-10:11:12 core-walltime
Job Wall-clock time: 00:32:03
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:33:43 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:32:33 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-10:44:16 core-walltime
Job Wall-clock time: 00:32:34
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:34:14 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:33:04 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-11:16:16 core-walltime
Job Wall-clock time: 00:33:04
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:34:45 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:33:35 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-11:49:20 core-walltime
Job Wall-clock time: 00:33:35
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:35:15 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:34:06 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-12:22:24 core-walltime
Job Wall-clock time: 00:34:06
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:35:46 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:34:38 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-12:56:32 core-walltime
Job Wall-clock time: 00:34:38
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:36:18 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:35:08 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-13:29:36 core-walltime
Job Wall-clock time: 00:35:09
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:36:49 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:35:39 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-14:01:36 core-walltime
Job Wall-clock time: 00:35:39
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:37:20 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:36:10 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-14:34:40 core-walltime
Job Wall-clock time: 00:36:10
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:37:50 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:36:40 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-15:07:44 core-walltime
Job Wall-clock time: 00:36:41
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:38:21 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:37:11 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-15:40:48 core-walltime
Job Wall-clock time: 00:37:12
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:38:52 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:37:43 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-16:14:56 core-walltime
Job Wall-clock time: 00:37:44
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:39:24 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491023 ArrayJobId=4490034 ArrayTaskId=323 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18458 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:38:14 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:01:10 EndTime=2025-09-21T18:01:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:01:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2187
   BatchHost=qnode2187
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491023
Array Job ID: 4490034_323
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-16:48:00 core-walltime
Job Wall-clock time: 00:38:15
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
