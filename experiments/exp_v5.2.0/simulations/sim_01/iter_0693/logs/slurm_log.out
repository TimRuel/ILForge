üìå Logging to experiments/exp_v5.2.0/simulations/sim_01/iter_0693/logs/slurm_log.out
git-lfs/3.3.0 (GitHub; linux amd64; go 1.20.3)
üîÅ Running Iteration 693 of Simulation sim_01 in Experiment exp_v5.2.0 (poisson / group_rates_weighted_sum/ fixed_effects_regression) with 64 cores...
[INFO] True parameters already exist ‚Äî skipping generation.
Generating data...
[‚úì] Saved config snapshot to: /gpfs/home/tbr0780/ILForge/experiments/exp_v5.2.0/simulations/sim_01/iter_0693/config_snapshot.yml
[INFO] Generating new data for iteration: iter_0693
[‚úì] Saved simulated data to: /gpfs/home/tbr0780/ILForge/experiments/exp_v5.2.0/simulations/sim_01/iter_0693/data
[INFO] Saved objects: data, X
Executing iteration...
üîç Computing branch parameters...
‚úÖ Branch parameters computed (2.25 min)
üîç Running integrated likelihood...
‚úÖ Integrated likelihood complete (7.73 min)
üìà Running profile likelihood...
‚úÖ Profile likelihood complete (4.83 min)
‚è±Ô∏è  Total experiment time: 14.81 minutes
‚úì Experiment results saved to /experiments/exp_v5.2.0/simulations/sim_01/iter_0693/results
‚úì Iteration completed
‚úÖ SLURM iteration complete: iter_0693
===== FINAL DIAGNOSTICS for Job 4492269 =====
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 16:39:28 core-walltime
Job Wall-clock time: 00:15:37
Memory Utilized: 0.00 MB
Memory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:15:37 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 16:39:28 core-walltime
Job Wall-clock time: 00:15:37
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
JobID                     JobName    Elapsed     MaxRSS     ReqMem  AllocCPUS      State 
------------ -------------------- ---------- ---------- ---------- ---------- ---------- 
4490034_692        experiment_sim   00:15:37                   64G         64    RUNNING 
4490034_692+                batch   00:15:37                               64    RUNNING 
4490034_692+               extern   00:15:37                               64    RUNNING 
              total        used        free      shared  buff/cache   available
Mem:          503Gi        42Gi       442Gi       5.3Gi        18Gi       449Gi
Swap:          31Gi       4.1Gi        27Gi
 17:32:46 up 11 days,  2:05,  1 user,  load average: 41.80, 55.45, 67.23
top - 17:32:46 up 11 days,  2:05,  1 user,  load average: 41.80, 55.45, 67.23
Tasks: 1253 total,  41 running, 1212 sleeping,   0 stopped,   0 zombie
%Cpu(s): 31.2 us,  0.1 sy,  0.0 ni, 68.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
MiB Mem : 515584.8 total, 453165.1 free,  43449.4 used,  18970.3 buff/cache
MiB Swap:  32768.0 total,  28562.3 free,   4205.7 used. 459963.5 avail Mem 

    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
  66586 xji7367   20   0 5378540 493048  46572 R 100.0   0.1   1829:28 vasp_std
  66587 xji7367   20   0 3377452 495948  46536 R 100.0   0.1   1829:36 vasp_std
  66591 xji7367   20   0 4149236 536720  46140 R 100.0   0.1   1828:44 vasp_std
  66596 xji7367   20   0   16.9g 541240  47908 R 100.0   0.1   1829:35 vasp_std
  66597 xji7367   20   0   13.3g 552308  47960 R 100.0   0.1   1829:32 vasp_std
  66606 xji7367   20   0 9857.5m 550844  47364 R 100.0   0.1   1829:25 vasp_std
  66610 xji7367   20   0 4321900 545352  47584 R 100.0   0.1   1829:18 vasp_std
  66613 xji7367   20   0   16.5g 541568  43892 R 100.0   0.1   1829:35 vasp_std
  66618 xji7367   20   0   11.2g 542236  44164 R 100.0   0.1   1829:25 vasp_std
  66580 xji7367   20   0 9626116 535248  54912 R  94.1   0.1   1829:25 vasp_std
  66581 xji7367   20   0 5961992 497968  46784 R  94.1   0.1   1829:31 vasp_std
  66582 xji7367   20   0 6309116 500048  46716 R  94.1   0.1   1829:38 vasp_std
  66583 xji7367   20   0 8882520 512000  50132 R  94.1   0.1   1829:28 vasp_std
  66584 xji7367   20   0   10.1g 499664  50540 R  94.1   0.1   1829:29 vasp_std
  66585 xji7367   20   0   15.3g 489940  50248 R  94.1   0.1   1829:37 vasp_std
  66588 xji7367   20   0 9501804 553716  46196 R  94.1   0.1   1829:26 vasp_std
  66589 xji7367   20   0   11.5g 538876  46240 R  94.1   0.1   1829:26 vasp_std
  66590 xji7367   20   0   14.9g 557340  50004 R  94.1   0.1   1829:36 vasp_std
  66592 xji7367   20   0 8344072 544268  45128 R  94.1   0.1   1829:24 vasp_std
  66593 xji7367   20   0   13.4g 537400  48976 R  94.1   0.1   1829:39 vasp_std
  66594 xji7367   20   0 8978260 542248  48904 R  94.1   0.1   1829:38 vasp_std
  66595 xji7367   20   0 9071704 555520  45232 R  94.1   0.1   1829:33 vasp_std
  66598 xji7367   20   0 2956968 545748  48076 R  94.1   0.1   1829:36 vasp_std
  66599 xji7367   20   0 9882488 546228  47720 R  94.1   0.1   1829:35 vasp_std
  66600 xji7367   20   0 8582368 549364  47864 R  94.1   0.1   1828:55 vasp_std
  66601 xji7367   20   0   12.8g 546988  46032 R  94.1   0.1   1829:41 vasp_std
  66602 xji7367   20   0   10.8g 543660  48076 R  94.1   0.1   1829:30 vasp_std
  66603 xji7367   20   0   10.9g 545548  47820 R  94.1   0.1   1829:30 vasp_std
  66604 xji7367   20   0 7681636 545052  47848 R  94.1   0.1   1829:42 vasp_std
  66605 xji7367   20   0   12.7g 545308  47048 R  94.1   0.1   1829:30 vasp_std
  66607 xji7367   20   0 9067768 543168  47084 R  94.1   0.1   1829:24 vasp_std
  66608 xji7367   20   0 7376260 546604  46368 R  94.1   0.1   1829:20 vasp_std
  66609 xji7367   20   0   13.0g 551360  47524 R  94.1   0.1   1829:31 vasp_std
===== BACKGROUND CHECKJOB MONITOR LOG =====
===== checkjob (interval) at Sun Sep 21 17:17:40 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:00:32 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 00:34:08 core-walltime
Job Wall-clock time: 00:00:32
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:18:12 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:01:06 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 01:10:24 core-walltime
Job Wall-clock time: 00:01:06
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:18:45 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:01:37 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 01:44:32 core-walltime
Job Wall-clock time: 00:01:38
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:19:17 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:02:09 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 02:17:36 core-walltime
Job Wall-clock time: 00:02:09
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:19:48 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:02:40 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 02:50:40 core-walltime
Job Wall-clock time: 00:02:40
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:20:20 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:03:16 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 03:34:24 core-walltime
Job Wall-clock time: 00:03:21
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:20:59 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:03:51 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 04:07:28 core-walltime
Job Wall-clock time: 00:03:52
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:21:31 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:04:23 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 04:41:36 core-walltime
Job Wall-clock time: 00:04:24
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:22:03 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:04:55 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 05:15:44 core-walltime
Job Wall-clock time: 00:04:56
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:22:34 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:05:27 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 05:48:48 core-walltime
Job Wall-clock time: 00:05:27
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:23:06 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:05:58 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 06:22:56 core-walltime
Job Wall-clock time: 00:05:59
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:23:38 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:06:30 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 06:57:04 core-walltime
Job Wall-clock time: 00:06:31
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:24:09 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:07:02 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 07:30:08 core-walltime
Job Wall-clock time: 00:07:02
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:24:41 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:07:33 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 08:04:16 core-walltime
Job Wall-clock time: 00:07:34
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:25:13 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:08:05 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 08:37:20 core-walltime
Job Wall-clock time: 00:08:05
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:25:43 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:08:35 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 09:10:24 core-walltime
Job Wall-clock time: 00:08:36
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:26:14 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:09:06 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 09:42:24 core-walltime
Job Wall-clock time: 00:09:06
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:26:45 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:09:37 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 10:15:28 core-walltime
Job Wall-clock time: 00:09:37
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:27:15 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:10:07 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 10:48:32 core-walltime
Job Wall-clock time: 00:10:08
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:27:46 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:10:38 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 11:20:32 core-walltime
Job Wall-clock time: 00:10:38
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:28:17 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:11:09 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 11:53:36 core-walltime
Job Wall-clock time: 00:11:09
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:28:47 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:11:39 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 12:26:40 core-walltime
Job Wall-clock time: 00:11:40
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:29:18 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:12:10 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 12:58:40 core-walltime
Job Wall-clock time: 00:12:10
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:29:49 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:12:41 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 13:31:44 core-walltime
Job Wall-clock time: 00:12:41
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:30:19 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:13:11 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 14:04:48 core-walltime
Job Wall-clock time: 00:13:12
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:30:50 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:13:42 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 14:36:48 core-walltime
Job Wall-clock time: 00:13:42
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:31:21 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:14:13 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 15:09:52 core-walltime
Job Wall-clock time: 00:14:13
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:31:51 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:14:43 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 15:42:56 core-walltime
Job Wall-clock time: 00:14:44
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:32:22 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492269 ArrayJobId=4490034 ArrayTaskId=692 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18400 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:15:14 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:17:08 EndTime=2025-09-21T19:17:08 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:17:08 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3087
   BatchHost=qnode3087
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492269
Array Job ID: 4490034_692
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 16:14:56 core-walltime
Job Wall-clock time: 00:15:14
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
