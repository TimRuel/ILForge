üìå Logging to experiments/exp_v5.2.0/simulations/sim_01/iter_0984/logs/slurm_log.out
git-lfs/3.3.0 (GitHub; linux amd64; go 1.20.3)
üîÅ Running Iteration 984 of Simulation sim_01 in Experiment exp_v5.2.0 (poisson / group_rates_weighted_sum/ fixed_effects_regression) with 64 cores...
[INFO] True parameters already exist ‚Äî skipping generation.
Generating data...
[‚úì] Saved config snapshot to: /gpfs/home/tbr0780/ILForge/experiments/exp_v5.2.0/simulations/sim_01/iter_0984/config_snapshot.yml
[INFO] Generating new data for iteration: iter_0984
[‚úì] Saved simulated data to: /gpfs/home/tbr0780/ILForge/experiments/exp_v5.2.0/simulations/sim_01/iter_0984/data
[INFO] Saved objects: data, X
Executing iteration...
üîç Computing branch parameters...
‚úÖ Branch parameters computed (2.76 min)
üîç Running integrated likelihood...
‚úÖ Integrated likelihood complete (10.46 min)
üìà Running profile likelihood...
‚úÖ Profile likelihood complete (5.77 min)
‚è±Ô∏è  Total experiment time: 18.99 minutes
‚úì Experiment results saved to /experiments/exp_v5.2.0/simulations/sim_01/iter_0984/results
‚úì Iteration completed
‚úÖ SLURM iteration complete: iter_0984
===== FINAL DIAGNOSTICS for Job 4492683 =====
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 21:09:20 core-walltime
Job Wall-clock time: 00:19:50
Memory Utilized: 0.00 MB
Memory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:19:50 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 21:09:20 core-walltime
Job Wall-clock time: 00:19:50
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
JobID                     JobName    Elapsed     MaxRSS     ReqMem  AllocCPUS      State 
------------ -------------------- ---------- ---------- ---------- ---------- ---------- 
4490034_983        experiment_sim   00:19:50                   64G         64    RUNNING 
4490034_983+                batch   00:19:50                               64    RUNNING 
4490034_983+               extern   00:19:50                               64    RUNNING 
              total        used        free      shared  buff/cache   available
Mem:          251Gi        21Gi       196Gi       7.8Gi        33Gi       215Gi
Swap:          31Gi       193Mi        31Gi
 18:35:28 up 11 days,  6:19,  0 users,  load average: 2.14, 11.18, 24.82
top - 18:35:29 up 11 days,  6:19,  0 users,  load average: 2.14, 11.18, 24.82
Tasks: 706 total,   1 running, 705 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.1 us,  0.1 sy,  0.0 ni, 99.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
MiB Mem : 257574.3 total, 200893.5 free,  22494.6 used,  34186.2 buff/cache
MiB Swap:  32768.0 total,  32574.8 free,    193.2 used. 220700.2 avail Mem 

    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
      1 root      20   0  238448  11392   8528 S   0.0   0.0   1:47.02 systemd
      2 root      20   0       0      0      0 S   0.0   0.0   0:00.38 kthreadd
      3 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 rcu_gp
      4 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 rcu_par+
      5 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 slub_fl+
      7 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker+
     11 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 mm_perc+
     12 root      20   0       0      0      0 S   0.0   0.0   0:00.00 rcu_tas+
     13 root      20   0       0      0      0 S   0.0   0.0   0:00.00 rcu_tas+
     14 root      20   0       0      0      0 S   0.0   0.0   0:05.93 ksoftir+
     15 root      20   0       0      0      0 I   0.0   0.0   5:55.74 rcu_sch+
     16 root      rt   0       0      0      0 S   0.0   0.0   0:00.71 migrati+
     17 root      rt   0       0      0      0 S   0.0   0.0   0:00.09 watchdo+
     18 root      20   0       0      0      0 S   0.0   0.0   0:00.33 cpuhp/0
     19 root      20   0       0      0      0 S   0.0   0.0   0:00.00 cpuhp/1
     20 root      rt   0       0      0      0 S   0.0   0.0   0:00.35 watchdo+
     21 root      rt   0       0      0      0 S   0.0   0.0   0:00.76 migrati+
     22 root      20   0       0      0      0 S   0.0   0.0   0:02.02 ksoftir+
     24 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker+
     25 root      20   0       0      0      0 S   0.0   0.0   0:00.00 cpuhp/2
     26 root      rt   0       0      0      0 S   0.0   0.0   0:00.32 watchdo+
     27 root      rt   0       0      0      0 S   0.0   0.0   0:01.06 migrati+
     28 root      20   0       0      0      0 S   0.0   0.0   0:02.16 ksoftir+
     30 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker+
     31 root      20   0       0      0      0 S   0.0   0.0   0:00.00 cpuhp/3
     32 root      rt   0       0      0      0 S   0.0   0.0   0:00.34 watchdo+
     33 root      rt   0       0      0      0 S   0.0   0.0   0:00.95 migrati+
     34 root      20   0       0      0      0 S   0.0   0.0   0:02.59 ksoftir+
     36 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker+
     37 root      20   0       0      0      0 S   0.0   0.0   0:00.00 cpuhp/4
     38 root      rt   0       0      0      0 S   0.0   0.0   0:00.35 watchdo+
     39 root      rt   0       0      0      0 S   0.0   0.0   0:00.94 migrati+
     40 root      20   0       0      0      0 S   0.0   0.0   0:02.51 ksoftir+
===== BACKGROUND CHECKJOB MONITOR LOG =====
===== checkjob (interval) at Sun Sep 21 18:16:17 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:00:39 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 00:41:36 core-walltime
Job Wall-clock time: 00:00:39
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:16:50 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:01:18 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 01:24:16 core-walltime
Job Wall-clock time: 00:01:19
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:17:27 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:01:50 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 01:57:20 core-walltime
Job Wall-clock time: 00:01:50
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:17:59 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:02:21 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 02:31:28 core-walltime
Job Wall-clock time: 00:02:22
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:18:31 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:02:53 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 03:04:32 core-walltime
Job Wall-clock time: 00:02:53
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:19:01 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:03:24 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 03:37:36 core-walltime
Job Wall-clock time: 00:03:24
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:19:35 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:04:03 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 04:20:16 core-walltime
Job Wall-clock time: 00:04:04
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:20:13 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:04:36 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 04:54:24 core-walltime
Job Wall-clock time: 00:04:36
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:20:45 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:05:08 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 05:28:32 core-walltime
Job Wall-clock time: 00:05:08
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:21:17 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:05:39 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 06:02:40 core-walltime
Job Wall-clock time: 00:05:40
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:21:49 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:06:11 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 06:36:48 core-walltime
Job Wall-clock time: 00:06:12
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:22:21 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:06:43 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 07:09:52 core-walltime
Job Wall-clock time: 00:06:43
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:22:52 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:07:14 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 07:44:00 core-walltime
Job Wall-clock time: 00:07:15
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:23:24 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:07:46 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 08:18:08 core-walltime
Job Wall-clock time: 00:07:47
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:23:56 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:08:18 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 08:52:16 core-walltime
Job Wall-clock time: 00:08:19
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:24:27 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:08:50 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 09:25:20 core-walltime
Job Wall-clock time: 00:08:50
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:24:59 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:09:22 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 09:59:28 core-walltime
Job Wall-clock time: 00:09:22
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:25:31 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:09:53 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 10:33:36 core-walltime
Job Wall-clock time: 00:09:54
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:26:02 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:10:24 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 11:05:36 core-walltime
Job Wall-clock time: 00:10:24
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:26:33 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:10:55 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 11:39:44 core-walltime
Job Wall-clock time: 00:10:56
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:27:04 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:11:26 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 12:12:48 core-walltime
Job Wall-clock time: 00:11:27
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:27:35 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:11:57 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 12:45:52 core-walltime
Job Wall-clock time: 00:11:58
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:28:06 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:12:28 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 13:17:52 core-walltime
Job Wall-clock time: 00:12:28
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:28:37 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:12:59 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 13:50:56 core-walltime
Job Wall-clock time: 00:12:59
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:29:07 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:13:30 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 14:24:00 core-walltime
Job Wall-clock time: 00:13:30
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:29:38 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:14:00 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 14:57:04 core-walltime
Job Wall-clock time: 00:14:01
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:30:09 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:14:31 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 15:29:04 core-walltime
Job Wall-clock time: 00:14:31
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:30:40 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:15:02 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 16:02:08 core-walltime
Job Wall-clock time: 00:15:02
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:31:10 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:15:33 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 16:35:12 core-walltime
Job Wall-clock time: 00:15:33
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:31:41 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:16:03 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 17:08:16 core-walltime
Job Wall-clock time: 00:16:04
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:32:12 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:16:34 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 17:40:16 core-walltime
Job Wall-clock time: 00:16:34
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:32:43 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:17:05 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 18:13:20 core-walltime
Job Wall-clock time: 00:17:05
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:33:13 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:17:35 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 18:46:24 core-walltime
Job Wall-clock time: 00:17:36
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:33:44 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:18:06 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 19:18:24 core-walltime
Job Wall-clock time: 00:18:06
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:34:15 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:18:37 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 19:51:28 core-walltime
Job Wall-clock time: 00:18:37
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:34:45 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:19:07 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 20:24:32 core-walltime
Job Wall-clock time: 00:19:08
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:35:16 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492683 ArrayJobId=4490034 ArrayTaskId=983 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18141 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:19:38 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T18:15:38 EndTime=2025-09-21T20:15:38 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T18:15:38 Scheduler=Backfill
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode2035
   BatchHost=qnode2035
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492683
Array Job ID: 4490034_983
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 20:57:36 core-walltime
Job Wall-clock time: 00:19:39
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
