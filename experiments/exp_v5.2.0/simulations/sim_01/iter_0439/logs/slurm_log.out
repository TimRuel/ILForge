üìå Logging to experiments/exp_v5.2.0/simulations/sim_01/iter_0439/logs/slurm_log.out
git-lfs/3.3.0 (GitHub; linux amd64; go 1.20.3)
üîÅ Running Iteration 439 of Simulation sim_01 in Experiment exp_v5.2.0 (poisson / group_rates_weighted_sum/ fixed_effects_regression) with 64 cores...
[INFO] True parameters already exist ‚Äî skipping generation.
Generating data...
[‚úì] Saved config snapshot to: /gpfs/home/tbr0780/ILForge/experiments/exp_v5.2.0/simulations/sim_01/iter_0439/config_snapshot.yml
[INFO] Generating new data for iteration: iter_0439
[‚úì] Saved simulated data to: /gpfs/home/tbr0780/ILForge/experiments/exp_v5.2.0/simulations/sim_01/iter_0439/data
[INFO] Saved objects: data, X
Executing iteration...
üîç Computing branch parameters...
‚úÖ Branch parameters computed (4.11 min)
üîç Running integrated likelihood...
‚úÖ Integrated likelihood complete (24.58 min)
üìà Running profile likelihood...
‚úÖ Profile likelihood complete (4.10 min)
‚è±Ô∏è  Total experiment time: 32.79 minutes
‚úì Experiment results saved to /experiments/exp_v5.2.0/simulations/sim_01/iter_0439/results
‚úì Iteration completed
‚úÖ SLURM iteration complete: iter_0439
===== FINAL DIAGNOSTICS for Job 4491144 =====
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-13:41:20 core-walltime
Job Wall-clock time: 00:35:20
Memory Utilized: 0.00 MB
Memory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:35:20 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-13:41:20 core-walltime
Job Wall-clock time: 00:35:20
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
JobID                     JobName    Elapsed     MaxRSS     ReqMem  AllocCPUS      State 
------------ -------------------- ---------- ---------- ---------- ---------- ---------- 
4490034_438        experiment_sim   00:35:21                   64G         64    RUNNING 
4490034_438+                batch   00:35:21                               64    RUNNING 
4490034_438+               extern   00:35:21                               64    RUNNING 
              total        used        free      shared  buff/cache   available
Mem:          251Gi        21Gi       220Gi       8.3Gi       9.4Gi       217Gi
Swap:          31Gi       0.0Ki        31Gi
 16:43:31 up 12 days,  5:49,  0 users,  load average: 1.61, 12.92, 32.29
top - 16:43:31 up 12 days,  5:49,  0 users,  load average: 1.61, 12.92, 32.29
Tasks: 711 total,   1 running, 710 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.1 us,  0.2 sy,  0.0 ni, 99.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
MiB Mem : 257574.4 total, 225878.3 free,  22093.5 used,   9602.5 buff/cache
MiB Swap:  32768.0 total,  32767.7 free,      0.3 used. 223011.0 avail Mem 

    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
 351811 tbr0780   20   0  269936   5292   3716 R  12.5   0.0   0:00.12 top
   2028 root      20   0  377224  20208  17464 S   6.2   0.0 366:54.73 Network+
      1 root      20   0  238408  11392   8568 S   0.0   0.0   8:09.40 systemd
      2 root      20   0       0      0      0 S   0.0   0.0   0:00.92 kthreadd
      3 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 rcu_gp
      4 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 rcu_par+
      5 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 slub_fl+
      7 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker+
     11 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 mm_perc+
     12 root      20   0       0      0      0 S   0.0   0.0   0:00.00 rcu_tas+
     13 root      20   0       0      0      0 S   0.0   0.0   0:00.00 rcu_tas+
     14 root      20   0       0      0      0 S   0.0   0.0   0:14.95 ksoftir+
     15 root      20   0       0      0      0 I   0.0   0.0  20:34.14 rcu_sch+
     16 root      rt   0       0      0      0 S   0.0   0.0   0:00.79 migrati+
     17 root      rt   0       0      0      0 S   0.0   0.0   0:00.10 watchdo+
     18 root      20   0       0      0      0 S   0.0   0.0   0:00.32 cpuhp/0
     19 root      20   0       0      0      0 S   0.0   0.0   0:00.00 cpuhp/1
     20 root      rt   0       0      0      0 S   0.0   0.0   0:00.82 watchdo+
     21 root      rt   0       0      0      0 S   0.0   0.0   0:00.91 migrati+
     22 root      20   0       0      0      0 S   0.0   0.0   0:03.39 ksoftir+
     24 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker+
     25 root      20   0       0      0      0 S   0.0   0.0   0:00.00 cpuhp/2
     26 root      rt   0       0      0      0 S   0.0   0.0   0:01.00 watchdo+
     27 root      rt   0       0      0      0 S   0.0   0.0   0:00.90 migrati+
     28 root      20   0       0      0      0 S   0.0   0.0   0:02.92 ksoftir+
     30 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker+
     31 root      20   0       0      0      0 S   0.0   0.0   0:00.00 cpuhp/3
     32 root      rt   0       0      0      0 S   0.0   0.0   0:00.99 watchdo+
     33 root      rt   0       0      0      0 S   0.0   0.0   0:00.97 migrati+
     34 root      20   0       0      0      0 S   0.0   0.0   0:02.47 ksoftir+
     36 root       0 -20       0      0      0 I   0.0   0.0   0:00.00 kworker+
     37 root      20   0       0      0      0 S   0.0   0.0   0:00.00 cpuhp/4
     38 root      rt   0       0      0      0 S   0.0   0.0   0:01.03 watchdo+
===== BACKGROUND CHECKJOB MONITOR LOG =====
===== checkjob (interval) at Sun Sep 21 16:10:20 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:02:11 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 02:19:44 core-walltime
Job Wall-clock time: 00:02:11
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:11:04 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:03:23 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 04:24:32 core-walltime
Job Wall-clock time: 00:04:08
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:12:49 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:04:39 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 04:58:40 core-walltime
Job Wall-clock time: 00:04:40
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:13:20 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:05:41 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 06:04:48 core-walltime
Job Wall-clock time: 00:05:42
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:14:22 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:06:12 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 06:37:52 core-walltime
Job Wall-clock time: 00:06:13
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:15:04 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:07:15 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 08:22:24 core-walltime
Job Wall-clock time: 00:07:51
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:16:32 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:08:22 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 08:56:32 core-walltime
Job Wall-clock time: 00:08:23
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:17:04 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:08:54 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 09:30:40 core-walltime
Job Wall-clock time: 00:08:55
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:17:35 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:09:26 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 10:03:44 core-walltime
Job Wall-clock time: 00:09:26
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:18:07 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:09:57 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 10:37:52 core-walltime
Job Wall-clock time: 00:09:58
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:18:39 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:10:29 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 11:12:00 core-walltime
Job Wall-clock time: 00:10:30
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:19:11 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:11:01 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 11:46:08 core-walltime
Job Wall-clock time: 00:11:02
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:19:42 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:11:33 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 12:19:12 core-walltime
Job Wall-clock time: 00:11:33
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:20:14 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:12:04 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 12:53:20 core-walltime
Job Wall-clock time: 00:12:05
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:20:46 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:12:36 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 13:27:28 core-walltime
Job Wall-clock time: 00:12:37
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:21:18 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:13:08 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 14:01:36 core-walltime
Job Wall-clock time: 00:13:09
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:21:50 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:13:40 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 14:35:44 core-walltime
Job Wall-clock time: 00:13:41
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:22:21 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:14:12 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 15:08:48 core-walltime
Job Wall-clock time: 00:14:12
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:22:53 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:14:43 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 15:42:56 core-walltime
Job Wall-clock time: 00:14:44
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:23:25 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:15:15 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 16:17:04 core-walltime
Job Wall-clock time: 00:15:16
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:23:57 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:15:47 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 16:51:12 core-walltime
Job Wall-clock time: 00:15:48
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:24:28 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:16:19 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 17:24:16 core-walltime
Job Wall-clock time: 00:16:19
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:25:00 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:16:50 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 17:58:24 core-walltime
Job Wall-clock time: 00:16:51
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:25:32 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:17:22 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 18:32:32 core-walltime
Job Wall-clock time: 00:17:23
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:26:04 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:17:54 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 19:06:40 core-walltime
Job Wall-clock time: 00:17:55
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:26:35 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:18:26 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 19:39:44 core-walltime
Job Wall-clock time: 00:18:26
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:27:07 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:18:57 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 20:13:52 core-walltime
Job Wall-clock time: 00:18:58
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:27:39 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:19:29 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 20:48:00 core-walltime
Job Wall-clock time: 00:19:30
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:28:11 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:20:01 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 21:24:16 core-walltime
Job Wall-clock time: 00:20:04
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:28:44 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:20:35 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 21:57:20 core-walltime
Job Wall-clock time: 00:20:35
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:29:16 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:21:06 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 22:31:28 core-walltime
Job Wall-clock time: 00:21:07
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:29:48 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:21:38 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 23:05:36 core-walltime
Job Wall-clock time: 00:21:39
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:30:20 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:22:10 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 23:39:44 core-walltime
Job Wall-clock time: 00:22:11
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:30:51 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:22:42 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-00:12:48 core-walltime
Job Wall-clock time: 00:22:42
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:31:23 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:23:14 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-00:48:00 core-walltime
Job Wall-clock time: 00:23:15
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:31:55 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:23:45 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-01:21:04 core-walltime
Job Wall-clock time: 00:23:46
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:32:27 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:24:17 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-01:54:08 core-walltime
Job Wall-clock time: 00:24:17
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:32:58 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:24:48 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-02:28:16 core-walltime
Job Wall-clock time: 00:24:49
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:33:29 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:25:19 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-03:01:20 core-walltime
Job Wall-clock time: 00:25:20
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:34:01 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:25:51 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-03:34:24 core-walltime
Job Wall-clock time: 00:25:51
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:34:32 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:26:22 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-04:08:32 core-walltime
Job Wall-clock time: 00:26:23
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:35:03 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:26:53 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-04:41:36 core-walltime
Job Wall-clock time: 00:26:54
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:35:35 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:27:25 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-05:14:40 core-walltime
Job Wall-clock time: 00:27:25
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:36:06 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:27:56 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-05:47:44 core-walltime
Job Wall-clock time: 00:27:56
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:36:37 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:28:27 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-06:21:52 core-walltime
Job Wall-clock time: 00:28:28
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:37:08 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:28:58 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-06:54:56 core-walltime
Job Wall-clock time: 00:28:59
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:37:39 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:29:30 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-07:28:00 core-walltime
Job Wall-clock time: 00:29:30
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:38:11 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:30:01 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-08:01:04 core-walltime
Job Wall-clock time: 00:30:01
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:38:42 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:30:32 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-08:35:12 core-walltime
Job Wall-clock time: 00:30:33
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:39:13 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:31:03 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-09:08:16 core-walltime
Job Wall-clock time: 00:31:04
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:39:44 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:31:34 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-09:41:20 core-walltime
Job Wall-clock time: 00:31:35
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:40:15 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:32:06 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-10:14:24 core-walltime
Job Wall-clock time: 00:32:06
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:40:47 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:32:37 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-10:47:28 core-walltime
Job Wall-clock time: 00:32:37
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:41:18 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:33:08 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-11:22:40 core-walltime
Job Wall-clock time: 00:33:10
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:41:50 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:33:40 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-11:55:44 core-walltime
Job Wall-clock time: 00:33:41
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:42:21 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:34:12 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-12:28:48 core-walltime
Job Wall-clock time: 00:34:12
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:42:53 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:34:43 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-13:01:52 core-walltime
Job Wall-clock time: 00:34:43
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 16:43:24 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4491144 ArrayJobId=4490034 ArrayTaskId=438 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18463 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:35:14 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T16:08:10 EndTime=2025-09-21T18:08:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T16:08:10 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode1053
   BatchHost=qnode1053
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4491144
Array Job ID: 4490034_438
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-13:34:56 core-walltime
Job Wall-clock time: 00:35:14
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
