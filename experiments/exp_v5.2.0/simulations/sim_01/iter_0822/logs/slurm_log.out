üìå Logging to experiments/exp_v5.2.0/simulations/sim_01/iter_0822/logs/slurm_log.out
git-lfs/3.3.0 (GitHub; linux amd64; go 1.20.3)
üîÅ Running Iteration 822 of Simulation sim_01 in Experiment exp_v5.2.0 (poisson / group_rates_weighted_sum/ fixed_effects_regression) with 64 cores...
[INFO] True parameters already exist ‚Äî skipping generation.
Generating data...
[‚úì] Saved config snapshot to: /gpfs/home/tbr0780/ILForge/experiments/exp_v5.2.0/simulations/sim_01/iter_0822/config_snapshot.yml
[INFO] Generating new data for iteration: iter_0822
[‚úì] Saved simulated data to: /gpfs/home/tbr0780/ILForge/experiments/exp_v5.2.0/simulations/sim_01/iter_0822/data
[INFO] Saved objects: data, X
Executing iteration...
üîç Computing branch parameters...
‚úÖ Branch parameters computed (2.40 min)
üîç Running integrated likelihood...
‚úÖ Integrated likelihood complete (19.41 min)
üìà Running profile likelihood...
‚úÖ Profile likelihood complete (4.92 min)
‚è±Ô∏è  Total experiment time: 26.73 minutes
‚úì Experiment results saved to /experiments/exp_v5.2.0/simulations/sim_01/iter_0822/results
‚úì Iteration completed
‚úÖ SLURM iteration complete: iter_0822
===== FINAL DIAGNOSTICS for Job 4492458 =====
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-05:50:56 core-walltime
Job Wall-clock time: 00:27:59
Memory Utilized: 0.00 MB
Memory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:27:59 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-05:52:00 core-walltime
Job Wall-clock time: 00:28:00
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
JobID                     JobName    Elapsed     MaxRSS     ReqMem  AllocCPUS      State 
------------ -------------------- ---------- ---------- ---------- ---------- ---------- 
4490034_821        experiment_sim   00:28:00                   64G         64    RUNNING 
4490034_821+                batch   00:28:00                               64    RUNNING 
4490034_821+               extern   00:28:00                               64    RUNNING 
              total        used        free      shared  buff/cache   available
Mem:          503Gi        35Gi       456Gi        10Gi        11Gi       452Gi
Swap:          31Gi        26Mi        31Gi
 18:15:12 up 11 days,  3:52,  0 users,  load average: 52.24, 61.03, 78.35
top - 18:15:13 up 11 days,  3:52,  0 users,  load average: 52.24, 61.03, 78.35
Tasks: 1271 total,  52 running, 1219 sleeping,   0 stopped,   0 zombie
%Cpu(s): 39.9 us,  0.2 sy,  0.0 ni, 59.9 id,  0.0 wa,  0.1 hi,  0.0 si,  0.0 st
MiB Mem : 515584.8 total, 467545.2 free,  36820.6 used,  11218.9 buff/cache
MiB Swap:  32768.0 total,  32742.0 free,     26.0 used. 464244.5 avail Mem 

    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
2523046 gbf0280   20   0 7898704 393344 139140 R 100.0   0.1   0:29.54 orca_le+
2523056 gbf0280   20   0   14.3g 363336 108948 R 100.0   0.1   0:29.27 orca_le+
2523060 gbf0280   20   0   10.4g 367092 110084 R 100.0   0.1   0:31.37 orca_le+
2523065 gbf0280   20   0   11.2g 362976 107912 R 100.0   0.1   0:29.11 orca_le+
2523072 gbf0280   20   0   13.6g 359360 104996 R 100.0   0.1   0:29.72 orca_le+
2523074 gbf0280   20   0 4644356 357552 103288 R 100.0   0.1   0:29.45 orca_le+
2523085 gbf0280   20   0   16.8g 367324 110204 R 100.0   0.1   0:29.28 orca_le+
2523090 gbf0280   20   0 3610724 361972 107028 R 100.0   0.1   0:29.44 orca_le+
2523091 gbf0280   20   0   12.0g 362436 108068 R 100.0   0.1   0:29.42 orca_le+
2523095 gbf0280   20   0 9300852 363528 109244 R 100.0   0.1   0:30.00 orca_le+
2523047 gbf0280   20   0   17.1g 391884 138064 R  94.1   0.1   0:29.11 orca_le+
2523048 gbf0280   20   0 5265992 365876 108708 R  94.1   0.1   0:29.29 orca_le+
2523049 gbf0280   20   0 5652584 360888 106100 R  94.1   0.1   0:29.10 orca_le+
2523050 gbf0280   20   0   16.4g 389400 137300 R  94.1   0.1   0:29.86 orca_le+
2523051 gbf0280   20   0   17.4g 365200 108280 R  94.1   0.1   0:29.88 orca_le+
2523052 gbf0280   20   0 9777172 367208 109720 R  94.1   0.1   0:29.17 orca_le+
2523053 gbf0280   20   0   16.9g 364900 108184 R  94.1   0.1   0:30.02 orca_le+
2523054 gbf0280   20   0 4739012 361160 105856 R  94.1   0.1   0:29.65 orca_le+
2523055 gbf0280   20   0   11.9g 363192 106092 R  94.1   0.1   0:29.15 orca_le+
2523057 gbf0280   20   0   12.7g 361996 105692 R  94.1   0.1   0:29.87 orca_le+
2523058 gbf0280   20   0   10.8g 357788 106724 R  94.1   0.1   0:30.12 orca_le+
2523059 gbf0280   20   0 1477732 363308 107788 R  94.1   0.1   0:30.72 orca_le+
2523061 gbf0280   20   0   14.6g 363604 107444 R  94.1   0.1   0:30.24 orca_le+
2523062 gbf0280   20   0 6949676 359088 104676 R  94.1   0.1   0:29.51 orca_le+
2523063 gbf0280   20   0   14.3g 360844 108888 R  94.1   0.1   0:29.86 orca_le+
2523064 gbf0280   20   0 9132088 362000 107760 R  94.1   0.1   0:29.89 orca_le+
2523066 gbf0280   20   0 5013360 363952 105096 R  94.1   0.1   0:30.96 orca_le+
2523067 gbf0280   20   0   10.2g 360008 105532 R  94.1   0.1   0:31.07 orca_le+
2523068 gbf0280   20   0 8095364 365120 108300 R  94.1   0.1   0:29.22 orca_le+
2523069 gbf0280   20   0   12.2g 367724 108548 R  94.1   0.1   0:29.64 orca_le+
2523070 gbf0280   20   0 6088172 360016 105580 R  94.1   0.1   0:29.65 orca_le+
2523071 gbf0280   20   0   12.7g 360692 103580 R  94.1   0.1   0:29.46 orca_le+
2523073 gbf0280   20   0 3226504 359700 104844 R  94.1   0.1   0:30.67 orca_le+
===== BACKGROUND CHECKJOB MONITOR LOG =====
===== checkjob (interval) at Sun Sep 21 17:48:13 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:01:01 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 01:05:04 core-walltime
Job Wall-clock time: 00:01:01
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:48:45 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:01:34 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 01:40:16 core-walltime
Job Wall-clock time: 00:01:34
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:49:17 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:02:05 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 02:14:24 core-walltime
Job Wall-clock time: 00:02:06
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:49:49 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:02:37 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 02:47:28 core-walltime
Job Wall-clock time: 00:02:37
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:50:20 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:03:08 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 03:20:32 core-walltime
Job Wall-clock time: 00:03:08
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:50:52 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:03:45 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 04:14:56 core-walltime
Job Wall-clock time: 00:03:59
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:51:44 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:04:32 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 04:50:08 core-walltime
Job Wall-clock time: 00:04:32
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:52:15 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:05:03 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 05:24:16 core-walltime
Job Wall-clock time: 00:05:04
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:52:47 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:05:35 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 05:58:24 core-walltime
Job Wall-clock time: 00:05:36
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:53:18 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:06:06 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 06:31:28 core-walltime
Job Wall-clock time: 00:06:07
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:53:50 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:06:38 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 07:05:36 core-walltime
Job Wall-clock time: 00:06:39
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:54:21 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:07:10 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 07:39:44 core-walltime
Job Wall-clock time: 00:07:11
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:54:53 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:07:41 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 08:12:48 core-walltime
Job Wall-clock time: 00:07:42
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:55:25 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:08:13 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 08:46:56 core-walltime
Job Wall-clock time: 00:08:14
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:55:57 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:08:45 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 09:21:04 core-walltime
Job Wall-clock time: 00:08:46
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:56:29 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:09:17 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 09:55:12 core-walltime
Job Wall-clock time: 00:09:18
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:57:01 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:09:49 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 10:29:20 core-walltime
Job Wall-clock time: 00:09:50
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:57:33 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:10:21 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 11:03:28 core-walltime
Job Wall-clock time: 00:10:22
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:58:05 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:10:53 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 11:37:36 core-walltime
Job Wall-clock time: 00:10:54
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:58:36 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:11:24 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 12:10:40 core-walltime
Job Wall-clock time: 00:11:25
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:59:08 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:11:56 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 12:44:48 core-walltime
Job Wall-clock time: 00:11:57
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 17:59:39 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:12:28 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 13:17:52 core-walltime
Job Wall-clock time: 00:12:28
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:00:11 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:12:59 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 13:52:00 core-walltime
Job Wall-clock time: 00:13:00
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:00:43 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:13:31 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 14:26:08 core-walltime
Job Wall-clock time: 00:13:32
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:01:15 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:14:03 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 15:00:16 core-walltime
Job Wall-clock time: 00:14:04
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:01:47 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:14:35 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 15:33:20 core-walltime
Job Wall-clock time: 00:14:35
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:02:18 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:15:07 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 16:07:28 core-walltime
Job Wall-clock time: 00:15:07
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:02:50 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:15:38 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 16:41:36 core-walltime
Job Wall-clock time: 00:15:39
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:03:22 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:16:10 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 17:14:40 core-walltime
Job Wall-clock time: 00:16:10
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:03:53 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:16:41 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 17:48:48 core-walltime
Job Wall-clock time: 00:16:42
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:04:25 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:17:13 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 18:21:52 core-walltime
Job Wall-clock time: 00:17:13
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:04:56 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:17:44 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 18:56:00 core-walltime
Job Wall-clock time: 00:17:45
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:05:27 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:18:15 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 19:28:00 core-walltime
Job Wall-clock time: 00:18:15
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:05:58 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:18:46 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 20:01:04 core-walltime
Job Wall-clock time: 00:18:46
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:06:28 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:19:16 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 20:34:08 core-walltime
Job Wall-clock time: 00:19:17
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:06:59 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:19:47 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 21:07:12 core-walltime
Job Wall-clock time: 00:19:48
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:07:30 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:20:18 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 21:39:12 core-walltime
Job Wall-clock time: 00:20:18
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:08:01 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:20:49 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 22:12:16 core-walltime
Job Wall-clock time: 00:20:49
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:08:31 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:21:19 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 22:45:20 core-walltime
Job Wall-clock time: 00:21:20
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:09:02 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:21:50 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 23:17:20 core-walltime
Job Wall-clock time: 00:21:50
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:09:33 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:22:21 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 23:50:24 core-walltime
Job Wall-clock time: 00:22:21
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:10:03 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:22:51 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-00:23:28 core-walltime
Job Wall-clock time: 00:22:52
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:10:34 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:23:22 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-00:55:28 core-walltime
Job Wall-clock time: 00:23:22
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:11:05 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:23:53 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-01:28:32 core-walltime
Job Wall-clock time: 00:23:53
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:11:36 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:24:24 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-02:01:36 core-walltime
Job Wall-clock time: 00:24:24
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:12:06 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:24:54 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-02:34:40 core-walltime
Job Wall-clock time: 00:24:55
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:12:37 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:25:25 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-03:07:44 core-walltime
Job Wall-clock time: 00:25:26
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:13:08 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:25:56 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-03:39:44 core-walltime
Job Wall-clock time: 00:25:56
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:13:39 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:26:27 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-04:12:48 core-walltime
Job Wall-clock time: 00:26:27
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:14:09 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:26:57 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-04:45:52 core-walltime
Job Wall-clock time: 00:26:58
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:14:40 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:27:28 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-05:17:52 core-walltime
Job Wall-clock time: 00:27:28
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
===== checkjob (interval) at Sun Sep 21 18:15:11 CDT 2025 =====
--------------------------------------------------------------------------------
JOB INFORMATION 
--------------------------------------------------------------------------------
JobId=4492458 ArrayJobId=4490034 ArrayTaskId=821 JobName=experiment_sim
   UserId=tbr0780(3229) GroupId=tbr0780(4023) MCS_label=N/A
   Priority=18430 Nice=0 Account=p32397 QOS=normal
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:27:59 TimeLimit=02:00:00 TimeMin=N/A
   SubmitTime=2025-09-21T15:28:52 EligibleTime=2025-09-21T15:28:52
   AccrueTime=2025-09-21T15:28:52
   StartTime=2025-09-21T17:47:12 EndTime=2025-09-21T19:47:12 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-09-21T17:47:12 Scheduler=Main
   Partition=short AllocNode:Sid=quser32:2678430
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=qnode3054
   BatchHost=qnode3054
   NumNodes=1 NumCPUs=64 NumTasks=1 CPUs/Task=64 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=64,mem=64G,node=1,billing=288
   AllocTRES=cpu=64,mem=64G,node=1,billing=288
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=64 MinMemoryNode=64G MinTmpDiskNode=0
   Features=[quest10|quest11|quest12|quest13] DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/home/tbr0780/ILForge/common/bash/launch_experiment2.sh
   WorkDir=/gpfs/home/tbr0780/ILForge
   StdErr=/dev/null
   StdIn=/dev/null
   StdOut=/dev/null
   TresPerTask=cpu=64
   MailUser=timothyruel2024@u.northwestern.edu MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   
--------------------------------------------------------------------------------
JOB EFFICIENCY 
--------------------------------------------------------------------------------
Job ID: 4492458
Array Job ID: 4490034_821
Cluster: quest
User/Group: tbr0780/tbr0780
State: RUNNING
Nodes: 1
Cores per node: 64
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-05:50:56 core-walltime
Job Wall-clock time: 00:27:59
Memory Utilized: 0.00 MB
[41mMemory Efficiency: 0.00% of 64.00 GB (64.00 GB/node)[0m
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
--------------------------------------------------------------------------------
JOB SCRIPT 
--------------------------------------------------------------------------------
#!/bin/bash
#SBATCH --account=p32397
#SBATCH --partition=short
#SBATCH --time=02:00:00
#SBATCH --mail-type=ALL
#SBATCH --mail-user=timothyruel2024@u.northwestern.edu
#SBATCH --job-name=experiment_sim
#SBATCH --output=/dev/null
#SBATCH --nodes=1
#SBATCH --ntasks=1                 # one R process
#SBATCH --cpus-per-task=64         # all forked workers come from this
#SBATCH --mem=64G                  # total memory for the task
#SBATCH --array=0-999

# ===============================
# ‚úÖ Validate CLI arguments
# ===============================
if [[ $# -ne 5 ]]; then
  echo "‚ùå ERROR: Missing arguments."
  echo "Usage: sbatch $0 <application_name> <estimand_name> <model_name> <experiment_id> <simulation_id>"
  exit 1
fi

APP_NAME="$1"
ESTIMAND="$2"
MODEL="$3"
EXP_ID="$4"
SIM_ID="$5"

ITER_NUM=$((SLURM_ARRAY_TASK_ID + 1))
ITER_ID=$(printf "iter_%04d" "$ITER_NUM")
REQUESTED_CORES=${SLURM_CPUS_PER_TASK:-1}

# ===============================
# ‚úÖ Resolve project root
# ===============================
PROJECT_ROOT="$SLURM_SUBMIT_DIR"
cd "$PROJECT_ROOT" || {
  echo "‚ùå ERROR: Failed to cd into SLURM_SUBMIT_DIR ($SLURM_SUBMIT_DIR)"
  exit 1
}
echo "üìÅ PROJECT_ROOT resolved to: $PROJECT_ROOT"

# ===============================
# ‚úÖ Logging setup
# ===============================
SIM_DIR="experiments/${EXP_ID}/simulations/${SIM_ID}"
ITER_DIR="${SIM_DIR}/${ITER_ID}"
LOG_DIR="${ITER_DIR}/logs"
mkdir -p "$LOG_DIR"

LOG_FILE="${LOG_DIR}/slurm_log.out"
CHECKJOB_MONITOR="${LOG_DIR}/checkjob_monitor.out"

exec > "$LOG_FILE" 2>&1
echo "üìå Logging to $LOG_FILE"

# ===============================
# ‚úÖ Load environment modules
# ===============================
module purge all
module load R/4.4.0
module load hdf5/1.14.1-2-gcc-12.3.0 
module load gsl/2.7.1-gcc-12.3.0 
module load fftw/3.3.10-gcc-12.3.0 
module load gdal/3.7.0-gcc-12.3.0
module load nlopt/2.7.1-gcc-12.3.0
module load git/2.37.2-gcc-10.4.0
module load chrome/114.0.5735.90
module load git-lfs/3.3.0-gcc-10.4.0

git lfs version || { echo "‚ùå git-lfs not available"; exit 1; }

# --- Limit BLAS threading conflicts (critical for multicore) ---
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1

echo "üîÅ Running Iteration $ITER_NUM of Simulation $SIM_ID in Experiment $EXP_ID ($APP_NAME / $ESTIMAND/ $MODEL) with $REQUESTED_CORES cores..."

# ===============================
# ‚úÖ Background checkjob monitor
# ===============================
(
  while true; do
    echo "===== checkjob (interval) at $(date) =====" >> "$CHECKJOB_MONITOR"
    checkjob "$SLURM_JOB_ID" >> "$CHECKJOB_MONITOR" 2>&1
    sleep 30
  done
) &
CHECKJOB_PID=$!

# ===============================
# ‚úÖ Cleanup diagnostics
# ===============================
trap '
  echo "===== FINAL DIAGNOSTICS for Job $SLURM_JOB_ID =====" >> "$LOG_FILE"
  seff "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  checkjob "$SLURM_JOB_ID" >> "$LOG_FILE" 2>&1
  sacct -j "$SLURM_JOB_ID" --format=JobID,JobName%20,Elapsed,MaxRSS,ReqMem,AllocCPUs,State >> "$LOG_FILE" 2>&1
  free -h >> "$LOG_FILE" 2>&1
  uptime >> "$LOG_FILE" 2>&1
  top -b -n 1 | head -40 >> "$LOG_FILE" 2>&1
  echo "===== BACKGROUND CHECKJOB MONITOR LOG =====" >> "$LOG_FILE"
  cat "$CHECKJOB_MONITOR" >> "$LOG_FILE" 2>/dev/null
  rm -f "$CHECKJOB_MONITOR"
  kill "$CHECKJOB_PID" 2>/dev/null
' EXIT

# ===============================
# ‚úÖ Run main R script
# ===============================
RSCRIPT_PATH="common/scripts/main.R"

if [[ ! -f "$RSCRIPT_PATH" ]]; then
  echo "‚ùå ERROR: Could not find R script at: $RSCRIPT_PATH"
  exit 1
fi

command -v Rscript >/dev/null 2>&1 || {
  echo "‚ùå ERROR: Rscript not found in PATH."
  exit 1
}

Rscript --max-connections=256 "$RSCRIPT_PATH" \
  "$APP_NAME" "$ESTIMAND" "$MODEL" "$EXP_ID" "$SIM_ID" "$ITER_ID" "$REQUESTED_CORES"

echo "‚úÖ SLURM iteration complete: $ITER_ID"
